---
title: "Excercise Manner Prediction using Machine Learning"
author: "Sukalpo Mitra"
date: "26 July 2015"
output: html_document
---

# Background

Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

# Required Libraries

Loading required libraries

```{r}
library(caret)
library(rattle)
library(randomForest)
```

# Data

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment. 

```{r, cache=TRUE}
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), na.strings=c("NA","#DIV/0!",""))
```

# Data Slicing

Partitioning the training data into two sets - 70% being considered as training and the rest as testing set.

```{r}
set.seed(125)
inTrain <- createDataPartition(training$classe, p = 0.7, list = F)
train <- training[inTrain,]
test <- training[-inTrain,]
```

# Feature Selection

A little study into the dataset reveals a lot of NA rows. Feature having a lot of NAs will not do any good. Let us first try to find all these features

```{r}
na_features = sapply(training, function(x) {sum(is.na(x))})
table(na_features)
```

As we can see there are 100 columns where the NA count is almost above 98%. So we would remove these columns from train, test and testing.

```{r}
featuresToRemove <- names(na_features[na_features > 0])
train <- train[,!names(train) %in% featuresToRemove]
test <- test[,!names(test) %in% featuresToRemove]
testing <- testing[,!names(testing) %in% featuresToRemove]
```

Let us also remove any near zero variance columns and the first few descriptive columns such as name and timestamps etc.,0

```{r}
nzvFeature <- nearZeroVar(train)
train <- train[, -nzvFeature]
test <- test[, -nzvFeature]
testing <- testing[, -nzvFeature]
train <- train[, -c(1:6)]
test <- test[, -c(1:6)]
testing <- testing[, -(1:6)]
```

Since the response variable is a categorical variable we will be using the following machine learning alsorithms and choose the best among them

- Decision Tree
- Random Forest

# Machine Learning Algorithm 1 : Decision Trees

```{r, cache=TRUE}
mod.dt <- train(classe~., data = train, method="rpart")
fancyRpartPlot(mod.dt$finalModel)
```

Calculating the out-of-sample error rate
```{r}
predict.dt <- predict(mod.dt, newdata = test)
confusionMatrix(predict.dt, test$classe)
```
The accuracy is 50% and hence the out of sample error is thus 50% and thus this model does not perform well.

# Machine Learning Algorithm 1 : Random Forest

```{r, cache=TRUE}
rfModel <- randomForest(classe ~ ., data = train, importance = TRUE, ntrees = 10)
```

Calculating the out-of-sample error rate
```{r}
predict.rf <- predict(rfModel, newdata = test)
confusionMatrix(predict.rf, test$classe)
```
The accuracy is 99% and hence the out of sample error is thus 1% and thus this model is fairly good.

# Testing Set Prediction

```{r}

predictions <- predict(rfModel,newdata = testing)
predictions
```

# Save the prediction

```{r}
answers <- as.vector(predictions)

pml_write_files = function(x) {
    n = length(x)
    for (i in 1:n) {
        filename = paste0("problem_id_", i, ".txt")
        write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, 
            col.names = FALSE)
    }
}

pml_write_files(answers)
```